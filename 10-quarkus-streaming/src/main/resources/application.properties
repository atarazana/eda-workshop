#
# Quarkus Properties
#
%dev.quarkus.http.port=8090

#
# Quarkus SmallRye Kafka connector
#
# Development Environment
%dev.kafka.bootstrap.servers=localhost:9092

# Test Profile
%test.kafka.bootstrap.servers=localhost:9092

# Production Environment
kafka.bootstrap.servers=${KAFKA_BOOTSTRAP_SERVERS:event-bus-kafka-bootstrap:9092}

# Apicurio Registry
%dev.mp.messaging.connector.smallrye-kafka.apicurio.registry.url=http://localhost:8080/apis/registry/v2
mp.messaging.connector.smallrye-kafka.apicurio.registry.url=http://eda-registry-service:8080/apis/registry/v2

# Consuming data from DBZ topics: Clients
mp.messaging.incoming.dbz-enterprise-clients.connector=smallrye-kafka
mp.messaging.incoming.dbz-enterprise-clients.topic=dbserver02.enterprise.clients
mp.messaging.incoming.dbz-enterprise-clients.auto.offset.reset=earliest
mp.messaging.incoming.dbz-enterprise-clients.isolation.level=read_committed
%dev.mp.messaging.incoming.dbz-enterprise-clients.group.id=quarkus-streaming-clients-dev
mp.messaging.incoming.dbz-enterprise-clients.group.id=quarkus-streaming-clients
mp.messaging.incoming.dbz-enterprise-clients.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#mp.messaging.incoming.dbz-enterprise-clients.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
mp.messaging.incoming.dbz-enterprise-clients.value.deserializer=com.redhat.banking.eda.cdc.serde.ClientDBDeserializer

# Consuming data from DBZ topics: Regions
mp.messaging.incoming.dbz-enterprise-regions.connector=smallrye-kafka
mp.messaging.incoming.dbz-enterprise-regions.topic=dbserver02.enterprise.regions
mp.messaging.incoming.dbz-enterprise-regions.auto.offset.reset=earliest
mp.messaging.incoming.dbz-enterprise-regions.isolation.level=read_committed
%dev.mp.messaging.incoming.dbz-enterprise-regions.group.id=quarkus-streaming-regions-dev
mp.messaging.incoming.dbz-enterprise-regions.group.id=quarkus-streaming-regions
mp.messaging.incoming.dbz-enterprise-regions.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#mp.messaging.incoming.dbz-enterprise-regions.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
mp.messaging.incoming.dbz-enterprise-regions.value.deserializer=com.redhat.banking.eda.cdc.serde.RegionDBDeserializer

# Consuming data from DBZ topics: Accounts
mp.messaging.incoming.dbz-enterprise-accounts.connector=smallrye-kafka
mp.messaging.incoming.dbz-enterprise-accounts.topic=dbserver02.enterprise.accounts
mp.messaging.incoming.dbz-enterprise-accounts.auto.offset.reset=earliest
mp.messaging.incoming.dbz-enterprise-accounts.isolation.level=read_committed
%dev.mp.messaging.incoming.dbz-enterprise-accounts.group.id=quarkus-streaming-accounts-dev
mp.messaging.incoming.dbz-enterprise-accounts.group.id=quarkus-streaming-accounts
mp.messaging.incoming.dbz-enterprise-accounts.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#mp.messaging.incoming.dbz-enterprise-accounts.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
mp.messaging.incoming.dbz-enterprise-accounts.value.deserializer=com.redhat.banking.eda.cdc.serde.AccountDBDeserializer

# Consuming data from DBZ topics: Movements
mp.messaging.incoming.dbz-enterprise-movements.connector=smallrye-kafka
mp.messaging.incoming.dbz-enterprise-movements.topic=dbserver02.enterprise.movements
mp.messaging.incoming.dbz-enterprise-movements.auto.offset.reset=earliest
mp.messaging.incoming.dbz-enterprise-movements.isolation.level=read_committed
%dev.mp.messaging.incoming.dbz-enterprise-movements.group.id=quarkus-streaming-movements-dev
mp.messaging.incoming.dbz-enterprise-movements.group.id=quarkus-streaming-movements
mp.messaging.incoming.dbz-enterprise-movements.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#mp.messaging.incoming.dbz-enterprise-movements.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
mp.messaging.incoming.dbz-enterprise-movements.value.deserializer=com.redhat.banking.eda.cdc.serde.MovementDBDeserializer

# Kafka Sink - Data Clients
mp.messaging.outgoing.data-clients.connector=smallrye-kafka
mp.messaging.outgoing.data-clients.topic=eda.data.clients
mp.messaging.outgoing.data-clients.acks=all
mp.messaging.outgoing.data-clients.key.serializer=org.apache.kafka.common.serialization.IntegerSerializer
mp.messaging.outgoing.data-clients.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer

# Kafka Sink - Data Accounts
mp.messaging.outgoing.data-accounts.connector=smallrye-kafka
mp.messaging.outgoing.data-accounts.topic=eda.data.accounts
mp.messaging.outgoing.data-accounts.acks=all
mp.messaging.outgoing.data-accounts.key.serializer=org.apache.kafka.common.serialization.IntegerSerializer
mp.messaging.outgoing.data-accounts.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer

# Kafka Sink - Data Regions
mp.messaging.outgoing.data-regions.connector=smallrye-kafka
mp.messaging.outgoing.data-regions.topic=eda.data.regions
mp.messaging.outgoing.data-regions.acks=all
mp.messaging.outgoing.data-regions.key.serializer=org.apache.kafka.common.serialization.IntegerSerializer
mp.messaging.outgoing.data-regions.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer

# Kafka Sink - Data Movements
mp.messaging.outgoing.data-movements.connector=smallrye-kafka
mp.messaging.outgoing.data-movements.topic=eda.data.movements
mp.messaging.outgoing.data-movements.acks=all
mp.messaging.outgoing.data-movements.key.serializer=org.apache.kafka.common.serialization.IntegerSerializer
mp.messaging.outgoing.data-movements.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer

# Kafka Sink - Alerts Accounts
mp.messaging.outgoing.eda-alerts-account.connector=smallrye-kafka
# To allow multiple streams
#mp.messaging.outgoing.eda-alerts.merge=true
mp.messaging.outgoing.eda-alerts-account.topic=eda.events.alerts
mp.messaging.outgoing.eda-alerts-account.acks=all
mp.messaging.outgoing.eda-alerts-account.key.serializer=org.apache.kafka.common.serialization.IntegerSerializer
mp.messaging.outgoing.eda-alerts-account.value.serializer=io.apicurio.registry.serde.avro.AvroKafkaSerializer
# Apicurio Properties
mp.messaging.outgoing.eda-alerts-account.apicurio.registry.headers.enabled=true
mp.messaging.outgoing.eda-alerts-account.apicurio.registry.auto-register=false
mp.messaging.outgoing.eda-alerts-account.apicurio.registry.avro.encoding=JSON
mp.messaging.outgoing.eda-alerts-account.apicurio.registry.artifact-resolver-strategy=io.apicurio.registry.serde.avro.strategy.RecordIdStrategy
mp.messaging.outgoing.eda-alerts-account.apicurio.registry.find-latest=true
#mp.messaging.outgoing.eda-alerts-account.apicurio.registry.avro-datum-provider=io.apicurio.registry.serde.avro.ReflectAvroDatumProvider

# Kafka Sink - Alerts Clients
mp.messaging.outgoing.eda-alerts-client.connector=smallrye-kafka
# To allow multiple streams
#mp.messaging.outgoing.eda-alerts.merge=true
mp.messaging.outgoing.eda-alerts-client.topic=eda.events.alerts
mp.messaging.outgoing.eda-alerts-client.acks=all
mp.messaging.outgoing.eda-alerts-client.key.serializer=org.apache.kafka.common.serialization.IntegerSerializer
mp.messaging.outgoing.eda-alerts-client.value.serializer=io.apicurio.registry.serde.avro.AvroKafkaSerializer
# Apicurio Properties
mp.messaging.outgoing.eda-alerts-client.apicurio.registry.headers.enabled=true
mp.messaging.outgoing.eda-alerts-client.apicurio.registry.auto-register=false
mp.messaging.outgoing.eda-alerts-client.apicurio.registry.avro.encoding=JSON
mp.messaging.outgoing.eda-alerts-client.apicurio.registry.artifact-resolver-strategy=io.apicurio.registry.serde.avro.strategy.RecordIdStrategy
mp.messaging.outgoing.eda-alerts-client.apicurio.registry.find-latest=true
#mp.messaging.outgoing.eda-alerts-client.apicurio.registry.avro-datum-provider=io.apicurio.registry.serde.avro.ReflectAvroDatumProvider

#
# Quarkus Kafka Streams
#

# Development Environment
%dev.quarkus.kafka-streams.bootstrap-servers=localhost:9092
%test.quarkus.kafka-streams.bootstrap-servers=localhost:9092

# Production Environment
quarkus.kafka-streams.bootstrap-servers=${KAFKA_BOOTSTRAP_SERVERS:event-bus-kafka-bootstrap:9092}

# Region and Accounts Aggregation Streams
%dev.quarkus.kafka-streams.application-id=quarkus-streaming-dev
quarkus.kafka-streams.application-id=quarkus-streaming
quarkus.kafka-streams.topics=eda.data.clients,eda.data.accounts,eda.data.movements,eda.data.regions,eda.events.domain.accounts

# streams options
kafka-streams.auto.offset.reset=earliest
kafka-streams.consumer.session.timeout.ms=250
kafka-streams.consumer.heartbeat.interval.ms=200
#kafka-streams.cache.max.bytes.buffering=10240
#kafka-streams.commit.interval.ms=1000
#kafka-streams.metadata.max.age.ms=500
#kafka-streams.metrics.recording.level=DEBUG

## Use sub-folder of embedded broker, so it gets cleaned by KafkaResource between re-runs
## This does not work for native tests, manually clean-up /tmp/kafka-streams/temperature-aggregator
#%test.kafka-streams.state.dir=target/data/kafka-data/stores

#
# OpenShift
#
# Recommended labels and a custom label for kubernetes and openshift
quarkus.openshift.part-of=eda-workshop
quarkus.openshift.name=data-streaming
quarkus.openshift.labels.eda=data-streaming
quarkus.openshift.labels.department=data-analytics

# Custom annotations
quarkus.openshift.annotations."app.openshift.io/connects-to"=event-bus-kafka

# Resources
quarkus.openshift.resources.requests.cpu=500m
quarkus.openshift.resources.requests.memory=1Gi
quarkus.openshift.resources.limits.cpu=1
quarkus.openshift.resources.limits.memory=1Gi

# Environment Variables
quarkus.openshift.env.vars.KAFKA_BOOTSTRAP_SERVERS=event-bus-kafka-bootstrap:9092
